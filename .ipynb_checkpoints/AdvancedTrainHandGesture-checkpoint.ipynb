{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32cfb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b984c5",
   "metadata": {},
   "source": [
    "# Speficy each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6b03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"HandGestureDataSet/model/number.csv\"\n",
    "model_save_path = 'HandGestureDataSet/model/hand_number.hdf5'\n",
    "tflite_save_path = 'HandGestureDataSet/model/hand_number.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dd69d",
   "metadata": {},
   "source": [
    "# Set number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723c8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259bb5f",
   "metadata": {},
   "source": [
    "# Dataset Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0109fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))\n",
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74152f2",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02ec75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f665c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                860       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 1,125\n",
      "Trainable params: 1,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57dc839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25442bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f9281",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba39866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 3s 218ms/step - loss: 1.6120 - accuracy: 0.2713 - val_loss: 1.5973 - val_accuracy: 0.3123\n",
      "\n",
      "Epoch 00001: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.5986 - accuracy: 0.2781 - val_loss: 1.5732 - val_accuracy: 0.3045\n",
      "\n",
      "Epoch 00002: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.5944 - accuracy: 0.2875 - val_loss: 1.5487 - val_accuracy: 0.2966\n",
      "\n",
      "Epoch 00003: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.5662 - accuracy: 0.2842 - val_loss: 1.5284 - val_accuracy: 0.2966\n",
      "\n",
      "Epoch 00004: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5453 - accuracy: 0.3051 - val_loss: 1.5097 - val_accuracy: 0.2992\n",
      "\n",
      "Epoch 00005: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.5279 - accuracy: 0.2900 - val_loss: 1.4891 - val_accuracy: 0.3045\n",
      "\n",
      "Epoch 00006: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.5066 - accuracy: 0.3045 - val_loss: 1.4712 - val_accuracy: 0.3123\n",
      "\n",
      "Epoch 00007: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4868 - accuracy: 0.3256 - val_loss: 1.4449 - val_accuracy: 0.3202\n",
      "\n",
      "Epoch 00008: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4657 - accuracy: 0.3418 - val_loss: 1.4093 - val_accuracy: 0.3202\n",
      "\n",
      "Epoch 00009: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4442 - accuracy: 0.3644 - val_loss: 1.3645 - val_accuracy: 0.3281\n",
      "\n",
      "Epoch 00010: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4044 - accuracy: 0.3872 - val_loss: 1.3174 - val_accuracy: 0.5381\n",
      "\n",
      "Epoch 00011: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.3829 - accuracy: 0.4234 - val_loss: 1.2686 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00012: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.3719 - accuracy: 0.4311 - val_loss: 1.2153 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00013: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.3475 - accuracy: 0.4499 - val_loss: 1.1654 - val_accuracy: 0.7008\n",
      "\n",
      "Epoch 00014: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.3140 - accuracy: 0.4821 - val_loss: 1.1166 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00015: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2705 - accuracy: 0.5040 - val_loss: 1.0711 - val_accuracy: 0.7402\n",
      "\n",
      "Epoch 00016: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2475 - accuracy: 0.4897 - val_loss: 1.0280 - val_accuracy: 0.7480\n",
      "\n",
      "Epoch 00017: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2141 - accuracy: 0.5196 - val_loss: 0.9878 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00018: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1812 - accuracy: 0.5243 - val_loss: 0.9405 - val_accuracy: 0.7848\n",
      "\n",
      "Epoch 00019: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.1524 - accuracy: 0.5386 - val_loss: 0.9045 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00020: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1302 - accuracy: 0.5398 - val_loss: 0.8698 - val_accuracy: 0.7848\n",
      "\n",
      "Epoch 00021: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1031 - accuracy: 0.5563 - val_loss: 0.8445 - val_accuracy: 0.7822\n",
      "\n",
      "Epoch 00022: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0788 - accuracy: 0.5572 - val_loss: 0.8086 - val_accuracy: 0.7848\n",
      "\n",
      "Epoch 00023: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0518 - accuracy: 0.5702 - val_loss: 0.7746 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00024: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0593 - accuracy: 0.5889 - val_loss: 0.7436 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00025: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0292 - accuracy: 0.5968 - val_loss: 0.7103 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00026: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0188 - accuracy: 0.5856 - val_loss: 0.6894 - val_accuracy: 0.8373\n",
      "\n",
      "Epoch 00027: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.9884 - accuracy: 0.6023 - val_loss: 0.6763 - val_accuracy: 0.8294\n",
      "\n",
      "Epoch 00028: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9739 - accuracy: 0.6255 - val_loss: 0.6526 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00029: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.9595 - accuracy: 0.6090 - val_loss: 0.6229 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00030: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9407 - accuracy: 0.6396 - val_loss: 0.5988 - val_accuracy: 0.9633\n",
      "\n",
      "Epoch 00031: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9113 - accuracy: 0.6418 - val_loss: 0.5837 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00032: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9293 - accuracy: 0.6515 - val_loss: 0.5631 - val_accuracy: 0.9633\n",
      "\n",
      "Epoch 00033: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8940 - accuracy: 0.6549 - val_loss: 0.5407 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00034: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8710 - accuracy: 0.6541 - val_loss: 0.5270 - val_accuracy: 0.9711\n",
      "\n",
      "Epoch 00035: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8742 - accuracy: 0.6596 - val_loss: 0.5165 - val_accuracy: 0.9711\n",
      "\n",
      "Epoch 00036: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8337 - accuracy: 0.6669 - val_loss: 0.5035 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00037: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8937 - accuracy: 0.6403 - val_loss: 0.4870 - val_accuracy: 0.9685\n",
      "\n",
      "Epoch 00038: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 12ms/step - loss: 0.8340 - accuracy: 0.6855 - val_loss: 0.4761 - val_accuracy: 0.9685\n",
      "\n",
      "Epoch 00039: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7839 - accuracy: 0.6899 - val_loss: 0.4613 - val_accuracy: 0.9685\n",
      "\n",
      "Epoch 00040: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8057 - accuracy: 0.6769 - val_loss: 0.4443 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00041: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7645 - accuracy: 0.7138 - val_loss: 0.4325 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00042: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7676 - accuracy: 0.7260 - val_loss: 0.4254 - val_accuracy: 0.9711\n",
      "\n",
      "Epoch 00043: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7992 - accuracy: 0.6833 - val_loss: 0.4187 - val_accuracy: 0.9711\n",
      "\n",
      "Epoch 00044: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7618 - accuracy: 0.6955 - val_loss: 0.4122 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00045: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7705 - accuracy: 0.6780 - val_loss: 0.3941 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00046: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7126 - accuracy: 0.7332 - val_loss: 0.3802 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00047: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7661 - accuracy: 0.6902 - val_loss: 0.3768 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00048: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.7455 - val_loss: 0.3712 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00049: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7010 - accuracy: 0.7293 - val_loss: 0.3604 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00050: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.7415 - val_loss: 0.3500 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00051: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6724 - accuracy: 0.7303 - val_loss: 0.3442 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00052: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7133 - accuracy: 0.7395 - val_loss: 0.3362 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00053: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6744 - accuracy: 0.7329 - val_loss: 0.3299 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00054: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6867 - accuracy: 0.7241 - val_loss: 0.3248 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00055: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6318 - accuracy: 0.7666 - val_loss: 0.3083 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00056: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6661 - accuracy: 0.7621 - val_loss: 0.3010 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00057: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7025 - accuracy: 0.7211 - val_loss: 0.3027 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00058: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6590 - accuracy: 0.7480 - val_loss: 0.3037 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00059: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7098 - accuracy: 0.7392 - val_loss: 0.3006 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00060: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5963 - accuracy: 0.7882 - val_loss: 0.2939 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00061: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6435 - accuracy: 0.7434 - val_loss: 0.2852 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00062: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6034 - accuracy: 0.7892 - val_loss: 0.2742 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00063: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6286 - accuracy: 0.7539 - val_loss: 0.2723 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00064: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6718 - accuracy: 0.7343 - val_loss: 0.2703 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00065: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5698 - accuracy: 0.7982 - val_loss: 0.2634 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00066: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6415 - accuracy: 0.7633 - val_loss: 0.2622 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00067: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6081 - accuracy: 0.7837 - val_loss: 0.2587 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00068: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6208 - accuracy: 0.7493 - val_loss: 0.2501 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00069: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6004 - accuracy: 0.7747 - val_loss: 0.2452 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00070: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6433 - accuracy: 0.7424 - val_loss: 0.2536 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00071: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5959 - accuracy: 0.7615 - val_loss: 0.2544 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00072: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5975 - accuracy: 0.7738 - val_loss: 0.2482 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00073: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5648 - accuracy: 0.7898 - val_loss: 0.2418 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00074: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6068 - accuracy: 0.7775 - val_loss: 0.2409 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00075: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5537 - accuracy: 0.7957 - val_loss: 0.2365 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00076: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5809 - accuracy: 0.7934 - val_loss: 0.2266 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00077: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6469 - accuracy: 0.7489 - val_loss: 0.2273 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00078: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5660 - accuracy: 0.7798 - val_loss: 0.2288 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00079: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5577 - accuracy: 0.7910 - val_loss: 0.2237 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00080: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5752 - accuracy: 0.7801 - val_loss: 0.2260 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00081: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6060 - accuracy: 0.7715 - val_loss: 0.2212 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00082: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5533 - accuracy: 0.7948 - val_loss: 0.2115 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00083: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5604 - accuracy: 0.7977 - val_loss: 0.2048 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00084: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5679 - accuracy: 0.7761 - val_loss: 0.2065 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00085: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5658 - accuracy: 0.7776 - val_loss: 0.2068 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00086: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5653 - accuracy: 0.7742 - val_loss: 0.2073 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00087: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5583 - accuracy: 0.7907 - val_loss: 0.2052 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00088: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5639 - accuracy: 0.7824 - val_loss: 0.2046 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00089: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5645 - accuracy: 0.7844 - val_loss: 0.2015 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00090: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5195 - accuracy: 0.8094 - val_loss: 0.1945 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00091: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4993 - accuracy: 0.8158 - val_loss: 0.1916 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00092: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5534 - accuracy: 0.7705 - val_loss: 0.1932 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00093: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5456 - accuracy: 0.7947 - val_loss: 0.1900 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00094: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5467 - accuracy: 0.7966 - val_loss: 0.1879 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00095: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5456 - accuracy: 0.7930 - val_loss: 0.1878 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00096: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5703 - accuracy: 0.8024 - val_loss: 0.1898 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00097: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4940 - accuracy: 0.8215 - val_loss: 0.1855 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00098: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5251 - accuracy: 0.8170 - val_loss: 0.1862 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00099: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5289 - accuracy: 0.8126 - val_loss: 0.1853 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00100: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5467 - accuracy: 0.7917 - val_loss: 0.1838 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00101: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4964 - accuracy: 0.8103 - val_loss: 0.1763 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00102: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5135 - accuracy: 0.7918 - val_loss: 0.1734 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00103: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5247 - accuracy: 0.8015 - val_loss: 0.1728 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00104: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4787 - accuracy: 0.8296 - val_loss: 0.1687 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00105: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4702 - accuracy: 0.8378 - val_loss: 0.1645 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00106: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5165 - accuracy: 0.7996 - val_loss: 0.1646 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00107: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5320 - accuracy: 0.7968 - val_loss: 0.1695 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00108: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5327 - accuracy: 0.7928 - val_loss: 0.1699 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00109: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5212 - accuracy: 0.8005 - val_loss: 0.1659 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00110: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5155 - accuracy: 0.7976 - val_loss: 0.1681 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00111: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4721 - accuracy: 0.8203 - val_loss: 0.1733 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00112: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4884 - accuracy: 0.8069 - val_loss: 0.1661 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00113: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4766 - accuracy: 0.8314 - val_loss: 0.1569 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00114: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4970 - accuracy: 0.8106 - val_loss: 0.1560 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00115: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5359 - accuracy: 0.8011 - val_loss: 0.1641 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00116: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4760 - accuracy: 0.8221 - val_loss: 0.1645 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00117: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5307 - accuracy: 0.7832 - val_loss: 0.1655 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00118: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4772 - accuracy: 0.8265 - val_loss: 0.1601 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00119: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5045 - accuracy: 0.8065 - val_loss: 0.1563 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00120: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4952 - accuracy: 0.8086 - val_loss: 0.1545 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00121: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4634 - accuracy: 0.8318 - val_loss: 0.1512 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00122: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5147 - accuracy: 0.7888 - val_loss: 0.1515 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00123: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5367 - accuracy: 0.7862 - val_loss: 0.1503 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00124: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4815 - accuracy: 0.8051 - val_loss: 0.1529 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00125: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4771 - accuracy: 0.8032 - val_loss: 0.1525 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00126: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4629 - accuracy: 0.8288 - val_loss: 0.1483 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00127: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4824 - accuracy: 0.8144 - val_loss: 0.1479 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00128: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4919 - accuracy: 0.8124 - val_loss: 0.1488 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00129: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4581 - accuracy: 0.8117 - val_loss: 0.1500 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00130: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4744 - accuracy: 0.8204 - val_loss: 0.1451 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00131: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4857 - accuracy: 0.8269 - val_loss: 0.1459 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00132: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4936 - accuracy: 0.8147 - val_loss: 0.1429 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00133: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4390 - accuracy: 0.8308 - val_loss: 0.1423 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00134: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 135/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4650 - accuracy: 0.8320 - val_loss: 0.1402 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00135: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 136/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4929 - accuracy: 0.8108 - val_loss: 0.1455 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00136: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 137/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4902 - accuracy: 0.8016 - val_loss: 0.1413 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00137: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 138/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4357 - accuracy: 0.8309 - val_loss: 0.1340 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00138: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 139/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.4958 - accuracy: 0.8122 - val_loss: 0.1343 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00139: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 140/1000\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4024 - accuracy: 0.8563 - val_loss: 0.1346 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00140: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 141/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4536 - accuracy: 0.8387 - val_loss: 0.1343 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00141: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 142/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4209 - accuracy: 0.8280 - val_loss: 0.1266 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00142: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 143/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4559 - accuracy: 0.8247 - val_loss: 0.1201 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00143: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 144/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4654 - accuracy: 0.8043 - val_loss: 0.1203 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00144: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 145/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4353 - accuracy: 0.8368 - val_loss: 0.1229 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00145: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 146/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4349 - accuracy: 0.8287 - val_loss: 0.1268 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00146: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 147/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4826 - accuracy: 0.8109 - val_loss: 0.1292 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00147: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 148/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4684 - accuracy: 0.8302 - val_loss: 0.1277 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00148: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 149/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4499 - accuracy: 0.8217 - val_loss: 0.1258 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00149: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 150/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4215 - accuracy: 0.8446 - val_loss: 0.1260 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00150: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 151/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4376 - accuracy: 0.8391 - val_loss: 0.1235 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00151: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 152/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4188 - accuracy: 0.8475 - val_loss: 0.1165 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00152: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4354 - accuracy: 0.8398 - val_loss: 0.1168 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00153: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 154/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4428 - accuracy: 0.8309 - val_loss: 0.1151 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00154: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 155/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.4099 - accuracy: 0.8504 - val_loss: 0.1170 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00155: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 156/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.4381 - accuracy: 0.8365 - val_loss: 0.1180 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00156: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 157/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4405 - accuracy: 0.8393 - val_loss: 0.1180 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00157: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 158/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4310 - accuracy: 0.8427 - val_loss: 0.1197 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00158: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 159/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.4272 - accuracy: 0.8396 - val_loss: 0.1252 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00159: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 160/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.4521 - accuracy: 0.8224 - val_loss: 0.1241 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00160: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 161/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.8538 - val_loss: 0.1226 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00161: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 162/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4387 - accuracy: 0.8361 - val_loss: 0.1197 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00162: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 163/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.4177 - accuracy: 0.8579 - val_loss: 0.1200 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00163: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 164/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4626 - accuracy: 0.8228 - val_loss: 0.1249 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00164: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 165/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4091 - accuracy: 0.8394 - val_loss: 0.1300 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00165: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 166/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4086 - accuracy: 0.8442 - val_loss: 0.1226 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00166: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 167/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4232 - accuracy: 0.8503 - val_loss: 0.1201 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00167: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 168/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4088 - accuracy: 0.8520 - val_loss: 0.1193 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00168: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 169/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4672 - accuracy: 0.8218 - val_loss: 0.1200 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00169: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 170/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 0.8193 - val_loss: 0.1193 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00170: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 171/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.4145 - accuracy: 0.8377 - val_loss: 0.1163 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00171: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 172/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4144 - accuracy: 0.8535 - val_loss: 0.1169 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00172: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 173/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4353 - accuracy: 0.8303 - val_loss: 0.1186 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00173: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 174/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4209 - accuracy: 0.8428 - val_loss: 0.1153 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00174: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 00174: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2016b744910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008955f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9843\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae68f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ccfb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8085778e-04 7.3397018e-02 9.1938668e-01 6.8965079e-03 3.8868213e-05]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ecc7e",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e01ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        43\n",
      "           1       0.95      0.97      0.96        77\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00       113\n",
      "           4       1.00      1.00      1.00        84\n",
      "\n",
      "    accuracy                           0.98       381\n",
      "   macro avg       0.98      0.98      0.98       381\n",
      "weighted avg       0.98      0.98      0.98       381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68b39d",
   "metadata": {},
   "source": [
    "# Convert Model to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7444066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb585e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmp97xr7z39\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform model (quantization)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b2284",
   "metadata": {},
   "source": [
    "# Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac7288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a558938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe5ed57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b15872f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51f5337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8085752e-04 7.3396988e-02 9.1938668e-01 6.8965079e-03 3.8868176e-05]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
