{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32cfb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b984c5",
   "metadata": {},
   "source": [
    "# Speficy each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6b03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"HandGestureDataSet/model/number.csv\"\n",
    "model_save_path = 'HandGestureDataSet/model/hand_number.hdf5'\n",
    "tflite_save_path = 'HandGestureDataSet/model/hand_number.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dd69d",
   "metadata": {},
   "source": [
    "# Set number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723c8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259bb5f",
   "metadata": {},
   "source": [
    "# Dataset Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0109fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))\n",
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74152f2",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02ec75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f665c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                860       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 66        \n",
      "=================================================================\n",
      "Total params: 1,136\n",
      "Trainable params: 1,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57dc839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25442bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f9281",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba39866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "43/43 [==============================] - 3s 46ms/step - loss: 1.8010 - accuracy: 0.2064 - val_loss: 1.7796 - val_accuracy: 0.3209\n",
      "\n",
      "Epoch 00001: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7833 - accuracy: 0.2122 - val_loss: 1.7500 - val_accuracy: 0.4092\n",
      "\n",
      "Epoch 00002: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7554 - accuracy: 0.2529 - val_loss: 1.7143 - val_accuracy: 0.4866\n",
      "\n",
      "Epoch 00003: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 4/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7385 - accuracy: 0.2655 - val_loss: 1.6532 - val_accuracy: 0.5464\n",
      "\n",
      "Epoch 00004: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 5/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6891 - accuracy: 0.3062 - val_loss: 1.5446 - val_accuracy: 0.6506\n",
      "\n",
      "Epoch 00005: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 6/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6248 - accuracy: 0.3474 - val_loss: 1.4317 - val_accuracy: 0.6473\n",
      "\n",
      "Epoch 00006: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 7/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.5657 - accuracy: 0.3863 - val_loss: 1.3292 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00007: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 8/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.4998 - accuracy: 0.4125 - val_loss: 1.2105 - val_accuracy: 0.6972\n",
      "\n",
      "Epoch 00008: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 9/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.4483 - accuracy: 0.4291 - val_loss: 1.1089 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00009: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 10/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.3707 - accuracy: 0.4658 - val_loss: 1.0092 - val_accuracy: 0.8042\n",
      "\n",
      "Epoch 00010: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 11/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.3402 - accuracy: 0.4797 - val_loss: 0.9421 - val_accuracy: 0.7899\n",
      "\n",
      "Epoch 00011: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 12/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.3053 - accuracy: 0.4871 - val_loss: 0.8959 - val_accuracy: 0.8343\n",
      "\n",
      "Epoch 00012: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 13/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.2661 - accuracy: 0.5017 - val_loss: 0.8499 - val_accuracy: 0.8579\n",
      "\n",
      "Epoch 00013: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 14/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.2417 - accuracy: 0.5146 - val_loss: 0.8224 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00014: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 15/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.2189 - accuracy: 0.5262 - val_loss: 0.7788 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00015: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 16/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.1747 - accuracy: 0.5408 - val_loss: 0.7456 - val_accuracy: 0.8859\n",
      "\n",
      "Epoch 00016: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 17/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.1173 - accuracy: 0.5732 - val_loss: 0.7096 - val_accuracy: 0.8903\n",
      "\n",
      "Epoch 00017: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 18/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0948 - accuracy: 0.5835 - val_loss: 0.6811 - val_accuracy: 0.8969\n",
      "\n",
      "Epoch 00018: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 19/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.1115 - accuracy: 0.5603 - val_loss: 0.6645 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00019: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 20/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0718 - accuracy: 0.5851 - val_loss: 0.6430 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00020: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 21/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0478 - accuracy: 0.6067 - val_loss: 0.6300 - val_accuracy: 0.9342\n",
      "\n",
      "Epoch 00021: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 22/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.0306 - accuracy: 0.6028 - val_loss: 0.6143 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00022: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 23/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0173 - accuracy: 0.6180 - val_loss: 0.5871 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00023: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 24/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.9934 - accuracy: 0.6199 - val_loss: 0.5828 - val_accuracy: 0.9386\n",
      "\n",
      "Epoch 00024: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 25/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0075 - accuracy: 0.6113 - val_loss: 0.5624 - val_accuracy: 0.9391\n",
      "\n",
      "Epoch 00025: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 26/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.9555 - accuracy: 0.6400 - val_loss: 0.5452 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00026: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 27/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.9415 - accuracy: 0.6449 - val_loss: 0.5517 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00027: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 28/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.9459 - accuracy: 0.6532 - val_loss: 0.5296 - val_accuracy: 0.9440\n",
      "\n",
      "Epoch 00028: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 29/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.9430 - accuracy: 0.6377 - val_loss: 0.5360 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00029: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 30/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.9025 - accuracy: 0.6577 - val_loss: 0.4997 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00030: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 31/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8920 - accuracy: 0.6812 - val_loss: 0.4937 - val_accuracy: 0.9622\n",
      "\n",
      "Epoch 00031: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 32/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8900 - accuracy: 0.6636 - val_loss: 0.4820 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00032: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 33/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8781 - accuracy: 0.6631 - val_loss: 0.4650 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00033: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 34/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8483 - accuracy: 0.6775 - val_loss: 0.4578 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00034: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 35/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8555 - accuracy: 0.6840 - val_loss: 0.4522 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00035: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 36/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8514 - accuracy: 0.6737 - val_loss: 0.4517 - val_accuracy: 0.9600\n",
      "\n",
      "Epoch 00036: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 37/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8421 - accuracy: 0.6940 - val_loss: 0.4276 - val_accuracy: 0.9643\n",
      "\n",
      "Epoch 00037: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 38/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8225 - accuracy: 0.6828 - val_loss: 0.4254 - val_accuracy: 0.9643\n",
      "\n",
      "Epoch 00038: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8229 - accuracy: 0.6968 - val_loss: 0.4381 - val_accuracy: 0.9578\n",
      "\n",
      "Epoch 00039: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 40/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8054 - accuracy: 0.7092 - val_loss: 0.4033 - val_accuracy: 0.9709\n",
      "\n",
      "Epoch 00040: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 41/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7780 - accuracy: 0.7170 - val_loss: 0.4119 - val_accuracy: 0.9682\n",
      "\n",
      "Epoch 00041: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 42/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7696 - accuracy: 0.7110 - val_loss: 0.4112 - val_accuracy: 0.9742\n",
      "\n",
      "Epoch 00042: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 43/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7750 - accuracy: 0.7194 - val_loss: 0.3846 - val_accuracy: 0.9638\n",
      "\n",
      "Epoch 00043: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 44/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7602 - accuracy: 0.7125 - val_loss: 0.3912 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00044: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 45/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7511 - accuracy: 0.7228 - val_loss: 0.3771 - val_accuracy: 0.9638\n",
      "\n",
      "Epoch 00045: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 46/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7556 - accuracy: 0.7238 - val_loss: 0.3797 - val_accuracy: 0.9687\n",
      "\n",
      "Epoch 00046: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 47/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7341 - accuracy: 0.7194 - val_loss: 0.3796 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00047: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 48/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7505 - accuracy: 0.7187 - val_loss: 0.3672 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00048: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 49/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7690 - accuracy: 0.7129 - val_loss: 0.3572 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00049: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 50/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7251 - accuracy: 0.7317 - val_loss: 0.3446 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00050: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 51/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7394 - accuracy: 0.7181 - val_loss: 0.3597 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00051: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 52/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7322 - accuracy: 0.7296 - val_loss: 0.3477 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00052: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 53/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7364 - accuracy: 0.7303 - val_loss: 0.3439 - val_accuracy: 0.9824\n",
      "\n",
      "Epoch 00053: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 54/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7283 - accuracy: 0.7308 - val_loss: 0.3520 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00054: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 55/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7110 - accuracy: 0.7356 - val_loss: 0.3388 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00055: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 56/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7202 - accuracy: 0.7440 - val_loss: 0.3406 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00056: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 57/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6969 - accuracy: 0.7515 - val_loss: 0.3300 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00057: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 58/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7128 - accuracy: 0.7409 - val_loss: 0.3299 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00058: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 59/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6732 - accuracy: 0.7465 - val_loss: 0.3363 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00059: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 60/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7043 - accuracy: 0.7398 - val_loss: 0.3280 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00060: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 61/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6977 - accuracy: 0.7449 - val_loss: 0.3235 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00061: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 62/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6763 - accuracy: 0.7517 - val_loss: 0.3162 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00062: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 63/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7139 - accuracy: 0.7317 - val_loss: 0.3154 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00063: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 64/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6847 - accuracy: 0.7475 - val_loss: 0.3208 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00064: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 65/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6621 - accuracy: 0.7634 - val_loss: 0.3093 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00065: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 66/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6541 - accuracy: 0.7548 - val_loss: 0.3069 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00066: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 67/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6868 - accuracy: 0.7472 - val_loss: 0.3130 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00067: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 68/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6502 - accuracy: 0.7592 - val_loss: 0.3006 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00068: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 69/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6648 - accuracy: 0.7574 - val_loss: 0.2967 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00069: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 70/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.6711 - accuracy: 0.7473 - val_loss: 0.3075 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00070: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 71/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.7569 - val_loss: 0.3002 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00071: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 72/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6700 - accuracy: 0.7431 - val_loss: 0.3070 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00072: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 73/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6578 - accuracy: 0.7671 - val_loss: 0.3136 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00073: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 74/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6260 - accuracy: 0.7784 - val_loss: 0.3029 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00074: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 75/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6626 - accuracy: 0.7561 - val_loss: 0.2931 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00075: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 76/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6619 - accuracy: 0.7568 - val_loss: 0.2944 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00076: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6535 - accuracy: 0.7538 - val_loss: 0.2938 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00077: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 78/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6634 - accuracy: 0.7691 - val_loss: 0.2970 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00078: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 79/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6204 - accuracy: 0.7761 - val_loss: 0.2757 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00079: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 80/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6551 - accuracy: 0.7552 - val_loss: 0.2939 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00080: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 81/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6410 - accuracy: 0.7715 - val_loss: 0.2914 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00081: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 82/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6169 - accuracy: 0.7796 - val_loss: 0.2738 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00082: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 83/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6589 - accuracy: 0.7631 - val_loss: 0.2888 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00083: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 84/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6301 - accuracy: 0.7769 - val_loss: 0.2776 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00084: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 85/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6236 - accuracy: 0.7745 - val_loss: 0.2878 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00085: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 86/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6373 - accuracy: 0.7651 - val_loss: 0.2841 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00086: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 87/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6369 - accuracy: 0.7611 - val_loss: 0.2988 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00087: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 88/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6300 - accuracy: 0.7767 - val_loss: 0.2752 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00088: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 89/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6211 - accuracy: 0.7709 - val_loss: 0.2997 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00089: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 90/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6470 - accuracy: 0.7687 - val_loss: 0.2841 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00090: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 91/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.7794 - val_loss: 0.2713 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00091: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 92/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6088 - accuracy: 0.7760 - val_loss: 0.2781 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00092: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 93/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6312 - accuracy: 0.7678 - val_loss: 0.2881 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00093: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 94/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6068 - accuracy: 0.7786 - val_loss: 0.2875 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00094: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 95/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6156 - accuracy: 0.7734 - val_loss: 0.2825 - val_accuracy: 0.9912\n",
      "\n",
      "Epoch 00095: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 96/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.7800 - val_loss: 0.2899 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00096: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 97/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6259 - accuracy: 0.7737 - val_loss: 0.2886 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00097: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 98/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6138 - accuracy: 0.7803 - val_loss: 0.2722 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00098: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 99/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.6166 - accuracy: 0.7701 - val_loss: 0.2883 - val_accuracy: 0.9907\n",
      "\n",
      "Epoch 00099: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 100/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.5943 - accuracy: 0.7842 - val_loss: 0.2826 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00100: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 101/1000\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.6045 - accuracy: 0.7834 - val_loss: 0.2775 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00101: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 102/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.5779 - accuracy: 0.7892 - val_loss: 0.2954 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00102: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 103/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.7875 - val_loss: 0.2897 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00103: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 104/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6101 - accuracy: 0.7802 - val_loss: 0.2811 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00104: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 105/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6027 - accuracy: 0.7818 - val_loss: 0.2735 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00105: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 106/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5814 - accuracy: 0.7949 - val_loss: 0.2920 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00106: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 107/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.7865 - val_loss: 0.2801 - val_accuracy: 0.9901\n",
      "\n",
      "Epoch 00107: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 108/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5967 - accuracy: 0.7899 - val_loss: 0.2797 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00108: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 109/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5868 - accuracy: 0.7890 - val_loss: 0.2887 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00109: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 110/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5724 - accuracy: 0.7947 - val_loss: 0.2711 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00110: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 111/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5887 - accuracy: 0.7969 - val_loss: 0.2638 - val_accuracy: 0.9907\n",
      "\n",
      "Epoch 00111: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 112/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5813 - accuracy: 0.7804 - val_loss: 0.2778 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00112: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 113/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5900 - accuracy: 0.7804 - val_loss: 0.2801 - val_accuracy: 0.9912\n",
      "\n",
      "Epoch 00113: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 114/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5817 - accuracy: 0.7891 - val_loss: 0.3018 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00114: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5931 - accuracy: 0.7906 - val_loss: 0.2910 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00115: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 116/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5689 - accuracy: 0.8037 - val_loss: 0.2894 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00116: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 117/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5885 - accuracy: 0.7772 - val_loss: 0.3026 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00117: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 118/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5404 - accuracy: 0.8058 - val_loss: 0.3012 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00118: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 119/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5603 - accuracy: 0.7975 - val_loss: 0.2793 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00119: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 120/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.5644 - accuracy: 0.8027 - val_loss: 0.2895 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00120: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 121/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.5657 - accuracy: 0.7993 - val_loss: 0.2787 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00121: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 122/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5570 - accuracy: 0.7989 - val_loss: 0.2966 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00122: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 123/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5435 - accuracy: 0.8054 - val_loss: 0.2874 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00123: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 124/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5779 - accuracy: 0.7939 - val_loss: 0.3030 - val_accuracy: 0.9720\n",
      "\n",
      "Epoch 00124: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 125/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5419 - accuracy: 0.8076 - val_loss: 0.2852 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00125: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 126/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5383 - accuracy: 0.8050 - val_loss: 0.2722 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00126: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 127/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5463 - accuracy: 0.8024 - val_loss: 0.2837 - val_accuracy: 0.9786\n",
      "\n",
      "Epoch 00127: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 128/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5802 - accuracy: 0.7880 - val_loss: 0.3004 - val_accuracy: 0.9786\n",
      "\n",
      "Epoch 00128: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 129/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5600 - accuracy: 0.7988 - val_loss: 0.3174 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00129: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 130/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5373 - accuracy: 0.8057 - val_loss: 0.2926 - val_accuracy: 0.9731\n",
      "\n",
      "Epoch 00130: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 131/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5243 - accuracy: 0.8141 - val_loss: 0.2989 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00131: saving model to HandGestureDataSet/model\\hand_number.hdf5\n",
      "Epoch 00131: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21dc1729370>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008955f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 4ms/step - loss: 0.2989 - accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae68f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ccfb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00202306 0.91124827 0.07467701 0.00688065 0.00323144 0.00193953]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ecc7e",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5e01ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       272\n",
      "           1       0.99      1.00      0.99       390\n",
      "           2       1.00      1.00      1.00       319\n",
      "           3       1.00      1.00      1.00       259\n",
      "           4       0.97      0.99      0.98       280\n",
      "           5       0.99      0.87      0.93       303\n",
      "\n",
      "    accuracy                           0.98      1823\n",
      "   macro avg       0.98      0.97      0.97      1823\n",
      "weighted avg       0.98      0.98      0.98      1823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68b39d",
   "metadata": {},
   "source": [
    "# Convert Model to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7444066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb585e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmptojjvlng\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6448"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform model (quantization)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b2284",
   "metadata": {},
   "source": [
    "# Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ac7288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a558938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe5ed57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b15872f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51f5337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00202307 0.91124827 0.07467702 0.00688066 0.00323144 0.00193953]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
